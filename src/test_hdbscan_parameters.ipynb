{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDBSCAN Parameter Testing\n",
    "\n",
    "This notebook helps you find optimal HDBSCAN parameters by testing different combinations on a sample of your data.\n",
    "\n",
    "**Purpose**: Before running full clustering on 27K speeches, test parameters on a smaller sample (5K speeches) to find the best settings.\n",
    "\n",
    "**What it tests**:\n",
    "- Different `min_cluster_size` values (30, 50, 75, 100, 150)\n",
    "- Different `min_samples` values (5, 10, 15, 20)\n",
    "- Metrics: number of clusters, outlier percentage, silhouette score, cluster sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import hdbscan\n",
    "from sklearn.metrics import silhouette_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better looking plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"‚úÖ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SAMPLE_SIZE = 5000  # Number of speeches to test on (adjust as needed)\n",
    "KEYWORDS_CSV = \"../data/speech_keywords.csv\"\n",
    "EMBEDDINGS_FILE = \"../data/keyword_embeddings.npy\"\n",
    "OUTPUT_RESULTS = \"../data/hdbscan_parameter_results.csv\"\n",
    "OUTPUT_PLOT = \"../data/hdbscan_parameter_test.png\"\n",
    "\n",
    "# Parameters to test\n",
    "MIN_CLUSTER_SIZES = [30, 50, 75, 100, 150]\n",
    "MIN_SAMPLES_LIST = [5, 10, 15, 20]\n",
    "METRICS = ['euclidean']\n",
    "\n",
    "print(f\"üìä Configuration:\")\n",
    "print(f\"   Sample size: {SAMPLE_SIZE:,}\")\n",
    "print(f\"   Testing {len(MIN_CLUSTER_SIZES)} √ó {len(MIN_SAMPLES_LIST)} √ó {len(METRICS)} = {len(MIN_CLUSTER_SIZES) * len(MIN_SAMPLES_LIST) * len(METRICS)} combinations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üì• Loading sample data (n={SAMPLE_SIZE:,})...\\n\")\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(KEYWORDS_CSV)\n",
    "print(f\"‚úÖ Loaded CSV: {len(df):,} total speeches\")\n",
    "\n",
    "# Sample randomly\n",
    "if SAMPLE_SIZE < len(df):\n",
    "    df_sample = df.sample(n=SAMPLE_SIZE, random_state=42)\n",
    "    indices = df_sample.index.tolist()\n",
    "    print(f\"   Sampled {len(df_sample):,} speeches for testing\")\n",
    "else:\n",
    "    df_sample = df\n",
    "    indices = list(range(len(df)))\n",
    "    print(f\"   Using all {len(df_sample):,} speeches\")\n",
    "\n",
    "# Load embeddings\n",
    "try:\n",
    "    embeddings = np.load(EMBEDDINGS_FILE)\n",
    "    embeddings_sample = embeddings[indices]\n",
    "    print(f\"\\n‚úÖ Loaded embeddings: {embeddings_sample.shape}\")\n",
    "    print(f\"   Dimension: {embeddings_sample.shape[1]}\")\n",
    "    print(f\"   Memory: {embeddings_sample.nbytes / 1e6:.2f} MB\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n‚ùå Error: Embeddings file not found at {EMBEDDINGS_FILE}\")\n",
    "    print(f\"   Please run the main clustering notebook first to generate embeddings.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test HDBSCAN Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_configuration(embeddings, min_cluster_size, min_samples, metric):\n",
    "    \"\"\"\n",
    "    Test a single HDBSCAN parameter configuration.\n",
    "    \n",
    "    Returns dict with results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run HDBSCAN\n",
    "        clusterer = hdbscan.HDBSCAN(\n",
    "            min_cluster_size=min_cluster_size,\n",
    "            min_samples=min_samples,\n",
    "            metric=metric\n",
    "        )\n",
    "        labels = clusterer.fit_predict(embeddings)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_outliers = np.sum(labels == -1)\n",
    "        outlier_pct = n_outliers / len(labels) * 100\n",
    "        \n",
    "        # Silhouette score (only if we have at least 2 clusters and not all outliers)\n",
    "        silhouette = None\n",
    "        if n_clusters >= 2 and n_outliers < len(labels):\n",
    "            mask = labels != -1\n",
    "            if mask.sum() > 0:\n",
    "                try:\n",
    "                    silhouette = silhouette_score(embeddings[mask], labels[mask])\n",
    "                except:\n",
    "                    silhouette = None\n",
    "        \n",
    "        # Cluster sizes\n",
    "        cluster_sizes = pd.Series(labels[labels != -1]).value_counts()\n",
    "        avg_cluster_size = cluster_sizes.mean() if len(cluster_sizes) > 0 else 0\n",
    "        min_size = cluster_sizes.min() if len(cluster_sizes) > 0 else 0\n",
    "        max_size = cluster_sizes.max() if len(cluster_sizes) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'min_cluster_size': min_cluster_size,\n",
    "            'min_samples': min_samples,\n",
    "            'metric': metric,\n",
    "            'n_clusters': n_clusters,\n",
    "            'n_outliers': n_outliers,\n",
    "            'outlier_pct': outlier_pct,\n",
    "            'silhouette': silhouette,\n",
    "            'avg_cluster_size': avg_cluster_size,\n",
    "            'min_size': min_size,\n",
    "            'max_size': max_size,\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'min_cluster_size': min_cluster_size,\n",
    "            'min_samples': min_samples,\n",
    "            'metric': metric,\n",
    "            'status': f'error: {str(e)}'\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Test function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all parameter combinations\n",
    "total_tests = len(MIN_CLUSTER_SIZES) * len(MIN_SAMPLES_LIST) * len(METRICS)\n",
    "\n",
    "print(f\"üî¨ Testing {total_tests} parameter combinations...\")\n",
    "print(f\"   min_cluster_size: {MIN_CLUSTER_SIZES}\")\n",
    "print(f\"   min_samples: {MIN_SAMPLES_LIST}\")\n",
    "print(f\"   metrics: {METRICS}\")\n",
    "print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "results = []\n",
    "test_num = 0\n",
    "\n",
    "for min_cluster_size, min_samples, metric in product(MIN_CLUSTER_SIZES, MIN_SAMPLES_LIST, METRICS):\n",
    "    test_num += 1\n",
    "    print(f\"[{test_num:2d}/{total_tests}] Testing: min_cluster_size={min_cluster_size:3d}, min_samples={min_samples:2d}, metric={metric}\")\n",
    "    \n",
    "    result = test_single_configuration(embeddings_sample, min_cluster_size, min_samples, metric)\n",
    "    results.append(result)\n",
    "    \n",
    "    if result.get('status') == 'success':\n",
    "        silhouette_str = f\"{result['silhouette']:.3f}\" if result['silhouette'] else 'N/A'\n",
    "        print(f\"         ‚Üí {result['n_clusters']:3d} clusters, {result['n_outliers']:5,} outliers ({result['outlier_pct']:5.1f}%), silhouette={silhouette_str}\")\n",
    "    else:\n",
    "        print(f\"         ‚ùå {result['status']}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df[results_df['status'] == 'success'].drop('status', axis=1)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ Testing complete! {len(results_df)} successful tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display full results table\n",
    "print(\"üìä All Results:\\n\")\n",
    "display_df = results_df.copy()\n",
    "display_df['silhouette'] = display_df['silhouette'].round(3)\n",
    "display_df['outlier_pct'] = display_df['outlier_pct'].round(1)\n",
    "display_df['avg_cluster_size'] = display_df['avg_cluster_size'].round(1)\n",
    "\n",
    "display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top configurations by different metrics\n",
    "print(\"=\"*80)\n",
    "print(\"TOP CONFIGURATIONS BY DIFFERENT METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìà Top 5 by Silhouette Score (higher is better):\")\n",
    "top_silhouette = results_df.nlargest(5, 'silhouette')[['min_cluster_size', 'min_samples', 'n_clusters', 'outlier_pct', 'silhouette', 'avg_cluster_size']]\n",
    "print(top_silhouette.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nüìä Top 5 by Number of Clusters (more granular topics):\")\n",
    "top_clusters = results_df.nlargest(5, 'n_clusters')[['min_cluster_size', 'min_samples', 'n_clusters', 'outlier_pct', 'silhouette', 'avg_cluster_size']]\n",
    "print(top_clusters.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nüéØ Lowest Outlier Percentage (more speeches clustered):\")\n",
    "low_outliers = results_df.nsmallest(5, 'outlier_pct')[['min_cluster_size', 'min_samples', 'n_clusters', 'outlier_pct', 'silhouette', 'avg_cluster_size']]\n",
    "print(low_outliers.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n‚öñÔ∏è  Balanced Configurations (moderate clusters, low outliers, good silhouette):\")\n",
    "# Score based on normalized metrics\n",
    "results_df['balance_score'] = (\n",
    "    (results_df['silhouette'].fillna(0) / results_df['silhouette'].max()) * 0.4 +\n",
    "    (1 - results_df['outlier_pct'] / results_df['outlier_pct'].max()) * 0.4 +\n",
    "    (results_df['n_clusters'] / results_df['n_clusters'].max()) * 0.2\n",
    ")\n",
    "balanced = results_df.nlargest(5, 'balance_score')[['min_cluster_size', 'min_samples', 'n_clusters', 'outlier_pct', 'silhouette', 'avg_cluster_size']]\n",
    "print(balanced.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Number of clusters vs min_cluster_size\n",
    "ax = axes[0, 0]\n",
    "for min_samples in sorted(results_df['min_samples'].unique()):\n",
    "    data = results_df[results_df['min_samples'] == min_samples].sort_values('min_cluster_size')\n",
    "    ax.plot(data['min_cluster_size'], data['n_clusters'], marker='o', linewidth=2, label=f'min_samples={min_samples}')\n",
    "ax.set_xlabel('min_cluster_size', fontsize=11)\n",
    "ax.set_ylabel('Number of Clusters', fontsize=11)\n",
    "ax.set_title('Number of Clusters vs min_cluster_size', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Outlier percentage vs min_cluster_size\n",
    "ax = axes[0, 1]\n",
    "for min_samples in sorted(results_df['min_samples'].unique()):\n",
    "    data = results_df[results_df['min_samples'] == min_samples].sort_values('min_cluster_size')\n",
    "    ax.plot(data['min_cluster_size'], data['outlier_pct'], marker='o', linewidth=2, label=f'min_samples={min_samples}')\n",
    "ax.set_xlabel('min_cluster_size', fontsize=11)\n",
    "ax.set_ylabel('Outlier Percentage (%)', fontsize=11)\n",
    "ax.set_title('Outlier Percentage vs min_cluster_size', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Silhouette score vs min_cluster_size\n",
    "ax = axes[1, 0]\n",
    "valid_silhouette = results_df[results_df['silhouette'].notna()]\n",
    "for min_samples in sorted(valid_silhouette['min_samples'].unique()):\n",
    "    data = valid_silhouette[valid_silhouette['min_samples'] == min_samples].sort_values('min_cluster_size')\n",
    "    ax.plot(data['min_cluster_size'], data['silhouette'], marker='o', linewidth=2, label=f'min_samples={min_samples}')\n",
    "ax.set_xlabel('min_cluster_size', fontsize=11)\n",
    "ax.set_ylabel('Silhouette Score', fontsize=11)\n",
    "ax.set_title('Silhouette Score vs min_cluster_size (higher is better)', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Average cluster size vs min_cluster_size\n",
    "ax = axes[1, 1]\n",
    "for min_samples in sorted(results_df['min_samples'].unique()):\n",
    "    data = results_df[results_df['min_samples'] == min_samples].sort_values('min_cluster_size')\n",
    "    ax.plot(data['min_cluster_size'], data['avg_cluster_size'], marker='o', linewidth=2, label=f'min_samples={min_samples}')\n",
    "ax.set_xlabel('min_cluster_size', fontsize=11)\n",
    "ax.set_ylabel('Average Cluster Size', fontsize=11)\n",
    "ax.set_title('Average Cluster Size vs min_cluster_size', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PLOT, dpi=150, bbox_inches='tight')\n",
    "print(f\"üíæ Saved visualization to: {OUTPUT_PLOT}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parameter Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PARAMETER RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best overall configuration\n",
    "best_idx = results_df['balance_score'].idxmax()\n",
    "best_config = results_df.loc[best_idx]\n",
    "\n",
    "print(f\"\\nüèÜ RECOMMENDED CONFIGURATION (Best Balanced):\")\n",
    "print(f\"   min_cluster_size = {int(best_config['min_cluster_size'])}\")\n",
    "print(f\"   min_samples = {int(best_config['min_samples'])}\")\n",
    "print(f\"   metric = '{best_config['metric']}'\")\n",
    "print(f\"\\n   Expected results:\")\n",
    "print(f\"   - Number of clusters: {int(best_config['n_clusters'])}\")\n",
    "print(f\"   - Outlier percentage: {best_config['outlier_pct']:.1f}%\")\n",
    "print(f\"   - Silhouette score: {best_config['silhouette']:.3f}\" if best_config['silhouette'] else \"   - Silhouette score: N/A\")\n",
    "print(f\"   - Average cluster size: {best_config['avg_cluster_size']:.0f}\")\n",
    "\n",
    "print(\"\\n\\nüí° GUIDELINES FOR ADJUSTING:\")\n",
    "print(\"\\n   For MORE fine-grained topics:\")\n",
    "print(\"   ‚Üí Use lower min_cluster_size (30-50)\")\n",
    "print(\"   ‚Üí This creates more, smaller clusters\")\n",
    "\n",
    "print(\"\\n   For FEWER, larger topics:\")\n",
    "print(\"   ‚Üí Use higher min_cluster_size (100-150)\")\n",
    "print(\"   ‚Üí This merges similar speeches into bigger clusters\")\n",
    "\n",
    "print(\"\\n   For FEWER outliers:\")\n",
    "print(\"   ‚Üí Decrease min_cluster_size AND min_samples\")\n",
    "print(\"   ‚Üí More speeches will be assigned to clusters\")\n",
    "\n",
    "print(\"\\n   For BETTER cluster quality:\")\n",
    "print(\"   ‚Üí Choose parameters with higher silhouette score\")\n",
    "print(\"   ‚Üí This indicates tighter, more separated clusters\")\n",
    "\n",
    "print(\"\\n\\nüìù NEXT STEPS:\")\n",
    "print(\"   1. Use the recommended parameters in the main clustering notebook\")\n",
    "print(\"   2. Run clustering on full dataset (27K speeches)\")\n",
    "print(\"   3. Inspect sample speeches from different clusters\")\n",
    "print(\"   4. Adjust parameters if needed and re-run\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed results to CSV\n",
    "results_df.to_csv(OUTPUT_RESULTS, index=False)\n",
    "print(f\"üíæ Saved detailed results to: {OUTPUT_RESULTS}\")\n",
    "print(f\"\\nüìä Results summary:\")\n",
    "print(f\"   Total configurations tested: {len(results_df)}\")\n",
    "print(f\"   Configurations with valid silhouette: {results_df['silhouette'].notna().sum()}\")\n",
    "print(f\"   File size: {pd.read_csv(OUTPUT_RESULTS).memory_usage(deep=True).sum() / 1024:.2f} KB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
