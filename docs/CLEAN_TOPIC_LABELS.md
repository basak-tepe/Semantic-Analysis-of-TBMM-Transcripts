# Topic Label Cleaning Guide

## Overview

This guide explains how to clean malformed topic labels in both your CSV files and Elasticsearch index.

## Problem

Some topic labels generated by the LLM contain extra formatting and explanations:

```
**baÅŸlÄ±k:** Deprem Ve Meclis GÃ¶rÃ¼ÅŸmeleri **gerekÃ§e:** - **anahtar Kelimeler** 
ArasÄ±nda "deprem", "rahmet", "allah", "diliyorum", "baÅŸkan", "teÅŸekkÃ¼r" Gibi 
Ifadeler Bulunuyor; Bu Kelimeler Genellikle...
```

This is:
- âŒ Too long (hundreds of characters)
- âŒ Not suitable for display
- âŒ Contains formatting markup
- âŒ Includes unnecessary explanations

## Solution

Extract just the topic name:

```
Deprem Ve Meclis GÃ¶rÃ¼ÅŸmeleri
```

---

## Cleaning Logic

The scripts apply these rules:

1. **Check length**: If `topic_label` â‰¤ 60 characters â†’ keep as-is
2. **Look for pattern**: If contains `**baÅŸlÄ±k:**` â†’ extract text until next `**`
3. **No pattern found**: Keep as-is (already clean or different format)

### Regex Pattern

```python
# Extract text between **baÅŸlÄ±k:** and next **
r'\*\*(?:baÅŸlÄ±k|baslik):\*\*\s*(.+?)\s*\*\*(?:gerekÃ§e|gerekce|\w+:)'
```

---

## Where to Clean

You need to clean topic labels in **TWO places**:

### 1. CSV File
- **File**: `data/topic_summary.csv`
- **Column**: `groq_topic_label`
- **Used by**: Your API for frontend display

### 2. Elasticsearch
- **Index**: `parliament_speeches`
- **Field**: `topic_label`
- **Used by**: Search and analysis queries

---

## Quick Start

### Option 1: Clean Everything at Once (Recommended)

```bash
cd scripts/
python clean_all_topic_labels.py
```

This runs both CSV and Elasticsearch cleaning in sequence.

### Option 2: Clean Separately

**Clean CSV only:**
```bash
cd scripts/
python clean_groq_topic_labels.py
```

**Clean Elasticsearch only:**
```bash
cd scripts/
python clean_elastic_topic_labels.py
```

---

## Detailed Instructions

### Cleaning CSV

#### What it does:
- Reads `data/topic_summary.csv`
- Creates backup: `data/topic_summary_backup.csv`
- Cleans `groq_topic_label` column
- Overwrites original file

#### Run it:
```bash
cd scripts/
python clean_groq_topic_labels.py
```

#### Output:
```
================================================================================
CLEANING GROQ TOPIC LABELS
================================================================================
Input: ../data/topic_summary.csv
Output: ../data/topic_summary.csv
Backup: ../data/topic_summary_backup.csv
================================================================================
âœ… Created backup: ../data/topic_summary_backup.csv

ðŸ“Š Statistics:
   Total rows: 7,296
   ðŸ”§ Cleaned: 3,458
   âœ“ Unchanged: 3,838
   âš ï¸  Empty/null: 0

ðŸ“‹ Sample Cleanings:
1. Original:
   **baÅŸlÄ±k:** Kamu Mali Denetim Ve Performans **gerekÃ§e:** ...
   Cleaned:
   Kamu Mali Denetim Ve Performans
```

---

### Cleaning Elasticsearch

#### What it does:
- Connects to Elasticsearch
- Finds documents with `topic_label` > 60 characters
- Extracts clean topic names
- Updates documents in batches

#### Prerequisites:
- Elasticsearch running at `http://localhost:9200`
- `parliament_speeches` index exists
- `topic_label` field has `.keyword` subfield (for length check)

#### Run it:
```bash
cd scripts/
python clean_elastic_topic_labels.py
```

#### Output:
```
================================================================================
ELASTICSEARCH TOPIC LABEL CLEANING
================================================================================
Index: parliament_speeches
Threshold: 60 characters
Pattern: Extract text after **baÅŸlÄ±k:** until next **
================================================================================
âœ… Connected to Elasticsearch at http://localhost:9200

âœ… Index 'parliament_speeches' found

ðŸ” Searching for documents with topic_label > 60 characters...
ðŸ“Š Found 2,456 documents to potentially clean

ðŸ§¹ Cleaning topic labels...

ðŸ“‹ Sample cleanings (showing 5):

1. Document ID: term27-year3-session21-48
   Original: **baÅŸlÄ±k:** Deprem Ve Meclis GÃ¶rÃ¼ÅŸmeleri **gerekÃ§e:** ...
   Cleaned:  Deprem Ve Meclis GÃ¶rÃ¼ÅŸmeleri

ðŸ’¾ Updating 2,456 documents in batches of 500...

================================================================================
ðŸ“Š CLEANING STATISTICS
================================================================================
Total documents checked: 2,456
ðŸ”§ Cleaned: 2,456
âœ“ Unchanged: 0
âŒ Errors: 0
================================================================================

âœ… Verifying cleaning...
âœ… All topic labels cleaned successfully!
```

---

## Examples

### Before Cleaning

**CSV (`groq_topic_label`):**
```csv
speech_giver,topic_id,topic_label,groq_topic_label
Mehmet MuÅŸ,0,0_000_2014_00_performans,"**baÅŸlÄ±k:** Kamu Mali Denetim Ve Performans **gerekÃ§e:** - **anahtar Kelimeler** ArasÄ±nda..."
```

**Elasticsearch (`topic_label`):**
```json
{
  "_id": "term27-year3-session21-48",
  "_source": {
    "speech_giver": "Ali Cumhur TaÅŸkÄ±n",
    "topic_label": "**baÅŸlÄ±k:** Deprem Ve Meclis GÃ¶rÃ¼ÅŸmeleri **gerekÃ§e:** - **anahtar Kelimeler** ArasÄ±nda..."
  }
}
```

### After Cleaning

**CSV:**
```csv
speech_giver,topic_id,topic_label,groq_topic_label
Mehmet MuÅŸ,0,0_000_2014_00_performans,Kamu Mali Denetim Ve Performans
```

**Elasticsearch:**
```json
{
  "_id": "term27-year3-session21-48",
  "_source": {
    "speech_giver": "Ali Cumhur TaÅŸkÄ±n",
    "topic_label": "Deprem Ve Meclis GÃ¶rÃ¼ÅŸmeleri"
  }
}
```

---

## Verification

### Verify CSV
```bash
# Check some cleaned labels
head -20 data/topic_summary.csv

# Count cleaned vs total
grep -c "baÅŸlÄ±k" data/topic_summary.csv  # Should be 0 or very low
```

### Verify Elasticsearch
```bash
# Check for remaining long labels
curl -X POST "http://localhost:9200/parliament_speeches/_search" \
  -H 'Content-Type: application/json' \
  -d '{
    "size": 5,
    "_source": ["topic_label"],
    "query": {
      "bool": {
        "filter": {
          "script": {
            "script": "doc[\"topic_label.keyword\"].value.length() > 60"
          }
        }
      }
    }
  }'

# Sample cleaned labels
curl -X POST "http://localhost:9200/parliament_speeches/_search" \
  -H 'Content-Type: application/json' \
  -d '{
    "size": 10,
    "_source": ["topic_label", "speech_giver"]
  }'
```

---

## API Integration

After cleaning, your API will automatically serve clean topic names:

```python
# In your API
topic_name = row['groq_topic_label']  # Now clean!
# Returns: "Kamu Mali Denetim Ve Performans"
```

No code changes needed - the data is now clean at the source!

---

## Troubleshooting

### Issue: CSV backup already exists
**Solution:** Delete or rename the existing backup file:
```bash
rm data/topic_summary_backup.csv
# or
mv data/topic_summary_backup.csv data/topic_summary_backup_old.csv
```

### Issue: Elasticsearch connection refused
**Solution:** Make sure Elasticsearch is running:
```bash
curl http://localhost:9200
```

### Issue: "No such field topic_label.keyword"
**Solution:** Add keyword subfield by running:
```bash
python scripts/update_speech_giver_mapping.py
```

Or update your index mapping to include:
```python
"topic_label": {
    "type": "text",
    "fields": {
        "keyword": {"type": "keyword"}
    }
}
```

### Issue: Some labels still not cleaned
**Cause:** Labels don't contain `**baÅŸlÄ±k:**` pattern (different format).

**Solution:** These are likely already clean or use a different format. You can:
1. Manually inspect them: `grep "^.{61,}" data/topic_summary.csv`
2. Add custom cleaning logic if needed
3. Re-run LLM topic naming with better prompts

---

## Recovery

### Restore CSV Backup
```bash
cp data/topic_summary_backup.csv data/topic_summary.csv
```

### Restore Elasticsearch (if you have backups)
```bash
# Restore from snapshot (if configured)
curl -X POST "http://localhost:9200/_snapshot/my_backup/snapshot_1/_restore"
```

---

## Performance

### CSV Cleaning
- **Speed**: ~7,000 rows in < 1 second
- **Memory**: Minimal (loads entire CSV)
- **Backup**: Automatic

### Elasticsearch Cleaning
- **Speed**: ~500 documents per second
- **Batch size**: 500 documents per bulk update
- **Downtime**: None (updates while running)
- **Rollback**: Manual (no automatic backup)

---

## Scripts Reference

| Script | Purpose | Location |
|--------|---------|----------|
| `clean_groq_topic_labels.py` | Clean CSV only | `scripts/` |
| `clean_elastic_topic_labels.py` | Clean Elasticsearch only | `scripts/` |
| `clean_all_topic_labels.py` | Clean both | `scripts/` |

---

## Next Steps

After cleaning:

1. âœ… Verify data in both places
2. âœ… Test API responses (should show clean labels)
3. âœ… Update frontend if needed (no changes likely required)
4. âœ… Consider improving LLM prompts to avoid this in future

---

## Preventing Future Issues

To avoid this problem with future topic naming:

1. **Update LLM prompt** in `src/llm_topic_namer.py`:
   - Request simpler output format
   - Ask for title only, no explanations
   - Limit to 5-10 words maximum

2. **Add validation** in topic modeling script:
   - Check label length before saving
   - Reject labels > 60 characters
   - Auto-clean during generation

3. **Use post-processing** in ingestion:
   - Clean labels before inserting to Elasticsearch
   - Add validation in ingestion scripts

---

## Summary

1. **Problem**: Topic labels contain formatting and are too long
2. **Solution**: Extract clean topic names using regex
3. **Where**: Clean both CSV and Elasticsearch
4. **How**: Run `python scripts/clean_all_topic_labels.py`
5. **Result**: Clean, display-ready topic names everywhere

Your topic labels are now clean and ready for production! ðŸŽ‰
